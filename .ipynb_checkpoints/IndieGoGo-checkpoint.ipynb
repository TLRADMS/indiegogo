{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: IndiGoGo GreenTech Success\n",
    "**Question/need**: What is the liklihood of successfully finishing my Energy/GreenTech funding?  \n",
    "\n",
    "**Description of my sample data**: Scrape profile URLs from IndiGoGo search/filter site, compile list of target URLs, then fetch data from list of target URLs   \n",
    "\n",
    "**Characteristics of each entity**: Description word count, number of backers, goal, location, final/current funding, existence/number of videos, existence/number of photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # path to the chromedriver executable\n",
    "chromedriver = r\"C:\\Users\\tyler\\Documents\\GitHub\\chromedriver.exe\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver) #launch the browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of URLs to Loop Through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_page_and_click_load_more(indiegogo_query, x):\n",
    "    '''\n",
    "    click the \"show more\" button x number of times; 10 is suggested as that is \n",
    "    roughly how many projects there are.\n",
    "    to be used in conjunction with get_url_list()\n",
    "    '''\n",
    "    driver.get(indiegogo_query)\n",
    "    for i in range(0, x):\n",
    "        time.sleep(2)\n",
    "        # see if the 'Load More' button is still available (if size is 1)\n",
    "        load_more_button = len(driver.find_elements_by_xpath(\"/html/body/div[2]/div/div/div[3]/explore-detail/div/div/div[3]/section[2]/div[3]/div[2]/div[1]/div/a\"))\n",
    "        # this if statement does not function as intended\n",
    "        # but code will still run - revisit if possible\n",
    "        if load_more_button > 0:\n",
    "            # click it!\n",
    "            driver.find_element_by_xpath(\"/html/body/div[2]/div/div/div[3]/explore-detail/div/div/div[3]/section[2]/div[3]/div[2]/div[1]/div/a\").click()\n",
    "    url_list = driver.find_elements_by_tag_name(\"a\")\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_list(url_list):\n",
    "    '''\n",
    "    parse list of target urls to be scraped\n",
    "    '''\n",
    "    return_list = []\n",
    "    for url in url_list:\n",
    "        project_link = url.get_attribute('href')\n",
    "        if '/projects/' in project_link:\n",
    "            return_list.append(project_link)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To run a shorter loop, change the number for click_load_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indiegogo_query='https://www.indiegogo.com/explore/energy-green-tech' # filtered for GreenTech only\n",
    "#greentech only doesn't have many inprogress\n",
    "# and only those projet in _prorgress have numbers on desired gaol\n",
    "# to delineate who is successful, presently, must change the search\n",
    "indiegogo_query = \"https://www.indiegogo.com/explore/all?project_type=campaign&project_timing=all&sort=trending\"\n",
    "click_load_more = 4\n",
    "url_list = open_page_and_click_load_more(indiegogo_query, click_load_more)\n",
    "url_list = get_url_list(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Objects to Parse and Loops Through List of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_url_text(url, soup):\n",
    "    '''\n",
    "    input: a beautifulsoup object from an IndiGogo url\n",
    "    output: a list of data specific to each IndiGogo project\n",
    "    '''\n",
    "    \n",
    "    # project title\n",
    "    title = soup.find(\"div\", class_=\"basicsSection-title is-hidden-tablet t-h3--sansSerif\").text.strip()\n",
    "    \n",
    "    # amount\n",
    "    amount = soup.find(\"span\", class_=\"basicsGoalProgress-amountSold t-h5--sansSerif t-weight--bold\").text.replace('$', '').replace(',', '').strip()\n",
    "    \n",
    "    #backers\n",
    "    backers = soup.find(\"span\", class_=\"basicsGoalProgress-claimedOrBackers\").text.strip().replace(' backers', '')\n",
    "    \n",
    "    # % of goal\n",
    "    percent_of_goal = soup.find(\"span\", class_=\"basicsGoalProgress-progressDetails-detailsGoal-goalPercentageOrInitiallyRaised\").text.replace('%', '').strip().split(' of ')[0]\n",
    "    if len(percent_of_goal) > 8:\n",
    "        return ''\n",
    "    \n",
    "    # number of campaigns / serial campaigner\n",
    "    number_of_campaigns = soup.find(\"div\", class_=\"basicsCampaignOwner-details-count\").text.strip().replace(' ', '').replace('\\n', '').replace('|', '').replace('Campaigns', '').replace('Campaign', '')\n",
    "    \n",
    "    # location\n",
    "    location = soup.find(\"div\", class_=\"basicsCampaignOwner-details-city\").text.strip()\n",
    "    \n",
    "    # time left\n",
    "    time_left = soup.find(\"div\", class_=\"basicsGoalProgress-progressDetails-detailsTimeLeft column t-body--sansSerif t-align--right\").text.replace(' ', '').replace(',', '').replace('[', '').replace(']', '').replace('daysleft','').strip()\n",
    "    \n",
    "    # give back structured data\n",
    "    return [url, title, amount, backers, percent_of_goal, number_of_campaigns, location, time_left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop through target URLs, keeping the time.sleep element\n",
    "def get_url_text(url):\n",
    "    '''\n",
    "    input: a string representation of a single URL\n",
    "    output: the full driver.page_source text of the provided URL\n",
    "    '''\n",
    "    driver.get(url) # to test this without querying a site, comment out this line...\n",
    "    driver.page_source # ...and this line\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml') # ... and this line\n",
    "    time.sleep(2) # ... and this\n",
    "    return(soup)\n",
    "\n",
    "        # print(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_url_list(url_list):\n",
    "    '''\n",
    "    This function receives a list of URLs, and loops through those. For each URL\n",
    "    it will call 2 other functions: get_url_text(), which performs the .get() function\n",
    "    using selenium, and parse_url_text(), which parses a soup object and returns a\n",
    "    list with parsed data from the same soup object.\n",
    "    ---\n",
    "    input: a list of string URLs and an empty dataframe\n",
    "    output: a dataframe with data from each URL in the list\n",
    "    '''\n",
    "    # this declares the df shape\n",
    "    columns = ['url', 'title', 'amount', 'backers', 'percent_of_goal', \n",
    "               'number_of_campaigns', 'location', 'time_left']\n",
    "    df = pd.DataFrame(columns=columns, dtype='str')\n",
    "    x=0\n",
    "    for url in url_list:\n",
    "        print('getting', x, 'of', len(url_list), url)\n",
    "        url_text = get_url_text(url) # calls another function\n",
    "        data = parse_url_text(url, url_text) # calls another function\n",
    "        if data == '':\n",
    "            pass\n",
    "        else:\n",
    "            df.loc[df.shape[0] + 1] = data\n",
    "        x+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kick Off Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting 0 of 599 https://www.indiegogo.com/projects/princube-the-world-s-smallest-mobile-color-printer/pica\n",
      "getting 1 of 599 https://www.indiegogo.com/projects/ciga-design-z-series-mechanical-titanium-watch--4/pica\n",
      "getting 2 of 599 https://www.indiegogo.com/projects/cash-grab-the-graphic-novel-by-cecil/pica\n",
      "getting 3 of 599 https://www.indiegogo.com/projects/scary-sleepover-the-resurrection/pica\n",
      "getting 4 of 599 https://www.indiegogo.com/projects/hyperjuice-world-s-first-100w-gan-usb-c-charger/pica\n",
      "getting 5 of 599 https://www.indiegogo.com/projects/thermosage-7-in-1-circulation-enhancing-massage/pica\n",
      "getting 6 of 599 https://www.indiegogo.com/projects/mr-charger-2-0-4-in-1-hybrid-charger/pica\n",
      "getting 7 of 599 https://www.indiegogo.com/projects/shine-ultra-next-gen-portable-powerful-scanner/pica\n",
      "getting 8 of 599 https://www.indiegogo.com/projects/incharge-6-the-swiss-army-knife-of-cables/pica\n",
      "getting 9 of 599 https://www.indiegogo.com/projects/being-alive/pica\n",
      "getting 10 of 599 https://www.indiegogo.com/projects/found-gps-world-s-longest-lasting-global-tracker/pica\n",
      "getting 11 of 599 https://www.indiegogo.com/projects/express-your-cinematic-side/pica\n",
      "getting 12 of 599 https://www.indiegogo.com/projects/dissociation-film-post-fundraiser/pica\n",
      "getting 13 of 599 https://www.indiegogo.com/projects/downcast-wrize-fall/pica\n",
      "getting 14 of 599 https://www.indiegogo.com/projects/dgrule-the-invisible-hub-for-macbook/pica\n",
      "getting 15 of 599 https://www.indiegogo.com/projects/bryan-james-new-album-politics-or-religion/pica\n",
      "getting 16 of 599 https://www.indiegogo.com/projects/total-loss-a-comedy-special-about-death/pica\n",
      "getting 17 of 599 https://www.indiegogo.com/projects/through-the-woods-collected-edition/pica\n",
      "getting 18 of 599 https://www.indiegogo.com/projects/nuflo-soundproof-anc-wireless-earbuds/pica\n",
      "getting 19 of 599 https://www.indiegogo.com/projects/switchbot-curtain-make-curtains-smart-in-seconds/pica\n",
      "getting 20 of 599 https://www.indiegogo.com/projects/seraphs-coal-through-all-these-years/pica\n",
      "getting 21 of 599 https://www.indiegogo.com/projects/the-click-beetles-pop-fossil/pica\n",
      "getting 22 of 599 https://www.indiegogo.com/projects/wuuk-the-world-s-most-advanced-smart-doorbell/pica\n",
      "getting 23 of 599 https://www.indiegogo.com/projects/song-x-tws-earbuds-sleek-design-great-sound/pica\n",
      "getting 24 of 599 https://www.indiegogo.com/projects/restoring-the-pile-of-bricks/pica\n",
      "getting 25 of 599 https://www.indiegogo.com/projects/joann-fabrix-music-video/pica\n",
      "getting 26 of 599 https://www.indiegogo.com/projects/grand-theft-gospel-we-shall-overcome/pica\n",
      "getting 27 of 599 https://www.indiegogo.com/projects/the-whale--2/pica\n",
      "getting 28 of 599 https://www.indiegogo.com/projects/the-anxiety-variety-show/pica\n",
      "getting 29 of 599 https://www.indiegogo.com/projects/fantasy-football-team-tokens-humans--3/pica\n",
      "getting 30 of 599 https://www.indiegogo.com/projects/the-elevated-craft-cocktail-shaker--2/pica\n",
      "getting 31 of 599 https://www.indiegogo.com/projects/niche-zero-the-best-conical-burr-coffee-grinder/pica\n",
      "getting 32 of 599 https://www.indiegogo.com/projects/monkii-360-4-min-workout-better-than-1-hour-run/pica\n",
      "getting 33 of 599 https://www.indiegogo.com/projects/pwnage-ultra-custom-wireless-gaming-mouse/pica\n",
      "getting 34 of 599 https://www.indiegogo.com/projects/draft-top-drink-topless/pica\n",
      "getting 35 of 599 https://www.indiegogo.com/projects/robotics-construction-kit-by-geeek-club/pica\n",
      "getting 36 of 599 https://www.indiegogo.com/projects/fingerbot-control-all-devices-via-voice-or-app/pica\n",
      "getting 37 of 599 https://www.indiegogo.com/projects/blackbird-sessions-the-new-relics-new-album/pica\n",
      "getting 38 of 599 https://www.indiegogo.com/projects/olivia-k-the-parkers-in-the-sankofa-project/pica\n",
      "getting 39 of 599 https://www.indiegogo.com/projects/grim-reaper-inc/pica\n",
      "getting 40 of 599 https://www.indiegogo.com/projects/jbl-reflect-eternal-self-charging-headphones/pica\n",
      "getting 41 of 599 https://www.indiegogo.com/projects/light-pink/pica\n",
      "getting 42 of 599 https://www.indiegogo.com/projects/the-redlander-by-zach-maberry/pica\n",
      "getting 43 of 599 https://www.indiegogo.com/projects/tempest-a-revolutionary-personal-weather-system/pica\n",
      "getting 44 of 599 https://www.indiegogo.com/projects/lvnthelife-on-lview-helping-the-disabled/pica\n",
      "getting 45 of 599 https://www.indiegogo.com/projects/laserpeckerpro-the-most-advanced-portable-engraver/pica\n",
      "getting 46 of 599 https://www.indiegogo.com/projects/blunderland-at-adelaide-fringe/pica\n",
      "getting 47 of 599 https://www.indiegogo.com/projects/steve-dawson-funeral-bonsai-wedding-with-strings/pica\n",
      "getting 48 of 599 https://www.indiegogo.com/projects/the-veganary-mini-tours/pica\n",
      "getting 49 of 599 https://www.indiegogo.com/projects/summer-in-mara-adventure-set-in-a-tropical-ocean/pica\n",
      "getting 50 of 599 https://www.indiegogo.com/projects/oh-the-places-you-won-t-go-a-parody/pica\n",
      "getting 51 of 599 https://www.indiegogo.com/projects/orson-welles-art-and-money-a-conversation/pica\n",
      "getting 52 of 599 https://www.indiegogo.com/projects/another-experimental-album/pica\n",
      "getting 53 of 599 https://www.indiegogo.com/projects/paranormal-investigators/pica\n",
      "getting 54 of 599 https://www.indiegogo.com/projects/the-final-rays-of-crimson/pica\n",
      "getting 55 of 599 https://www.indiegogo.com/projects/space3d-the-most-affordable-10-1in-sla-3d-printer/pica\n",
      "getting 56 of 599 https://www.indiegogo.com/projects/pangea-bamboo-travel-towel/pica\n",
      "getting 57 of 599 https://www.indiegogo.com/projects/midea-ultifree-window-air-conditioner-reinvented/coming_soon/pica\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-542a23835349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_through_url_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# can run a subset of this list if preferred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-0f20a176b172>\u001b[0m in \u001b[0;36mloop_through_url_list\u001b[1;34m(url_list)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'getting'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0murl_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_url_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calls another function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_url_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_text\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calls another function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-f49eb35dcbe9>\u001b[0m in \u001b[0;36mparse_url_text\u001b[1;34m(url, soup)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# project title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"basicsSection-title is-hidden-tablet t-h3--sansSerif\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# amount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "df = loop_through_url_list(url_list[1:]) # can run a subset of this list if preferred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(\"C:\\\\Users\\\\tyler\\\\Documents\\\\GitHub\\\\sf20_ds17\\\\curriculum\\\\project-02\\\\Project_Precipitation\\\\indigogo3.pkl\")\n",
    "\n",
    "df = pd.read_pickle(\"C:\\\\Users\\\\tyler\\\\Documents\\\\GitHub\\\\sf20_ds17\\\\curriculum\\\\project-02\\\\Project_Precipitation\\\\indigogo4.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjusting Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['amount'] = pd.to_numeric(df['amount'])\n",
    "df['backers'] = pd.to_numeric(df['backers'])\n",
    "df['number_of_campaigns'] = pd.to_numeric(df['number_of_campaigns'])\n",
    "df['percent_of_goal'] = pd.to_numeric(df['percent_of_goal'])\n",
    "df['time_left'] = pd.to_numeric(df['time_left'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generation and Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['goal'] = df['amount']/(0.0001+df['percent_of_goal']*.01) # add 0.0001 to avoid inifinite and NaN\n",
    "df['title_length'] = df['title'].str.split().apply(len)\n",
    "\n",
    "# split out to country only, then get_dummies\n",
    "df['country'] = df['location'].str.split(',').str[1]\n",
    "df = pd.get_dummies(df, columns = ['country'], drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This undoes a good bit of the *get_dummies()* but it should help the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country_ Other'] = df['country_ Argentina'] + df['country_ Australia'] + df['country_ Canada'] + df['country_ Dorset']\n",
    "+ df['country_ Ecuador'] + df['country_ Finland'] + df['country_ Georgia'] + df['country_ Germany']\n",
    "+ df['country_ Italy'] + df['country_ Netherlands'] + df['country_ Panama'] + df['country_ Portugal']\n",
    "+ df['country_ Sweden'] + df['country_ Turkey'] + df['country_ United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.append(removed_data) # to undo data removal\n",
    "before = df.shape\n",
    "df = df[df['amount'] < 60000]\n",
    "print('before', before, 'after', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "goal_plot = df['goal']\n",
    "sns.distplot(goal_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop the now-defunct columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['country_ Argentina', 'country_ Australia', 'country_ Canada', 'country_ Dorset',\n",
    "'country_ Ecuador', 'country_ Finland', 'country_ Georgia', 'country_ Germany',\n",
    "'country_ Italy', 'country_ Netherlands', 'country_ Panama', 'country_ Portugal',\n",
    "'country_ Sweden', 'country_ Turkey', 'country_ United Kingdom'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['url', 'title', 'location', 'goal', 'title_length'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_labels = ['Amount', 'Backers', 'Percent\\nof Goal', 'Number of\\nCampaigns', 'Time Left', 'Denamrk', 'United\\nStates', 'Other\\nCountry']\n",
    "plt.figure(figsize=(12,12))\n",
    "heat = sns.heatmap(df.corr(), square=True, annot=True, linewidths=0, cmap=\"BuGn_r\", fmt='.2g', xticklabels=axis_labels, yticklabels=axis_labels, cbar=False)\n",
    "heat.axes.set_title(\"IndieGoGo Feature Correlation\",fontsize=40, color='w')\n",
    "heat.tick_params(axis='both', labelsize=20, colors='white')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=360)\n",
    "plt.savefig(\"heatmap.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr = corr.sort_values('amount', ascending=False)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "might need to click \"continue reading\" \n",
    "---\n",
    "Additional Feature Ideas:\n",
    "\n",
    "Social Media Presence\n",
    "1. Likes/Reactions\n",
    "2. Retweets\n",
    "3. Responses\n",
    "Length of Story -- are more words better?\n",
    "Count of Perks -- Is more perks more value?\n",
    "Values of Perks -- Is there a perfect pricepoint?\n",
    "Number of Pictures\n",
    "Separate feature for 100% +++ -- what makes extreme success?\n",
    "Project Tags -- is there an out performing tag?\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With data as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :1]\n",
    "y = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "model = LinearRegression()\n",
    "model = model.fit(X_train, y_train)\n",
    "# model.summary()\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_train)\n",
    "coef_list = list(zip(model.coef_, list(df.columns[1:])))\n",
    "for coef in coef_list:\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 2)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#scale values\n",
    "min_max_scaler.fit(X_train)\n",
    "X_train_scaled = min_max_scaler.transform(X_train)\n",
    "X_test_scaled = min_max_scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_list = []\n",
    "\n",
    "for i in range(52):    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=i)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #scale values\n",
    "    min_max_scaler.fit(X_train)\n",
    "    X_train_scaled = min_max_scaler.transform(X_train)\n",
    "    X_test_scaled = min_max_scaler.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    model_results_list.append(score)\n",
    "    \n",
    "import statistics\n",
    "print(statistics.mean(model_results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_train_scaled)\n",
    "coef_list = list(zip(model.coef_, list(df.columns[1:])))\n",
    "for coef in coef_list:\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions vs Actuals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Amount Raised\",fontsize=40, color='w')\n",
    "plt.scatter(y_test, y_pred, s=50, alpha=0.7, c='w')\n",
    "plt.xlabel('Measured', fontsize=30, color='white')\n",
    "plt.ylabel('Predicted', fontsize=30, color='white')\n",
    "plt.tick_params(axis='both', labelsize=20, colors='white')\n",
    "plt.plot(y_pred, y_pred, 'k--', lw=2)\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('xkcd:grey green')\n",
    "plt.savefig(\"linechart.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict = lasso.predict(X_test_scaled)\n",
    "\n",
    "coef_list = list(zip(lasso.coef_, list(df.columns[1:])))\n",
    "for coef in coef_list:\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.1)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "y_pred = ridge.predict(X_test_scaled)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(X_train_scaled, y_train)\n",
    "model = model.fit()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
